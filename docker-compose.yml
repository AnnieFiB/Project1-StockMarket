# Project1-StockMarket
name: project1-stockmarket

services:

# ---- Spark Master ----
  spark-master:
    image: spark:3.5.1-python3
    container_name: spark-master
    hostname: spark-master
    networks: [stock_market]
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "7077:7077"
      - "8080:8080"
    command: ["/opt/spark/bin/spark-class",
              "org.apache.spark.deploy.master.Master",
              "--host","spark-master",
              "--port","7077",
              "--webui-port","8080"]

  # ---- Spark Worker ----
  spark-worker:
    image: spark:3.5.1-python3
    container_name: spark-worker
    hostname: spark-worker
    networks: [stock_market]
    depends_on:
      spark-master:
        condition: service_started
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    ports:
      - "8081:8081"
    command: ["/opt/spark/bin/spark-class",
              "org.apache.spark.deploy.worker.Worker",
              "spark://spark-master:7077",
              "--webui-port","8081"]
    healthcheck:
      test: ["CMD-SHELL", "</dev/tcp/127.0.0.1/8081 >/dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 20
      start_period: 40s

# ----  Kafka â†’ Spark â†’ Postgres (consumer.py) ----
  consumer:
    build:
      context: .
      dockerfile: spark/Dockerfile
    container_name: consumer
    restart: unless-stopped
    depends_on:
      spark-master: { condition: service_started }
      spark-worker: { condition: service_started }
      kafka:        { condition: service_healthy }
      postgres:     { condition: service_healthy }
    networks: [stock_market]
    environment:
      TZ: UTC
      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: "stock_intraday_5min"
      # Postgres
      POSTGRES_HOST: postgres
      POSTGRES_PORT: "5432"
      POSTGRES_DB: ${POSTGRES_DB:-market_pulse}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
      TARGET_TABLE: ${TARGET_TABLE:-public.events_stream}

  # ---- API â†’ Kafka Producer (producer.py) ----
  producer:
    build:
      context: ./api
      dockerfile: Dockerfile
    image: stock-api:latest
    container_name: producer
    networks: [stock_market]
    depends_on:
      kafka:
        condition: service_healthy
      spark-worker:
        condition: service_started   # wait until the stream process is up
    environment:
      IN_DOCKER: ${IN_DOCKER}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: ${KAFKA_TOPIC}
      SYMBOL: ${SYMBOL}
      POLL_INTERVAL_SEC: ${POLL_INTERVAL_SEC}
      RAPIDAPI_KEY: ${RAPIDAPI_KEY}
      X_RAPIDAPI_HOST: ${X_RAPIDAPI_HOST}
    command: ["sh","-lc","sleep ${PRODUCER_START_DELAY:-15}; exec python -u producer.py"]
    healthcheck:
      test: ["CMD-SHELL", "python - <<'PY'\nimport socket,sys\ns=socket.socket(); s.settimeout(3)\ntry:\n  s.connect(('kafka',9092)); s.close(); sys.exit(0)\nexcept: sys.exit(1)\nPY"]
      interval: 30s
      timeout: 5s
      retries: 10
      start_period: 20s
  
  # ---- Kafka (KRaft, single broker) ----
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    hostname: kafka
    networks: [stock_market]
    ports:
      - "9092:9092"
    environment:
      # your existing KRaft env stays here
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_RETENTION_MS: 86400000      # 24h
      KAFKA_LOG_RETENTION_BYTES: -1         # no size cap
      KAFKA_LOG_CLEANUP_POLICY: delete
    volumes:
      - kafka_data:/var/lib/kafka
    healthcheck:
      test: ["CMD-SHELL", "bash -lc '</dev/tcp/127.0.0.1/9092' >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 40s

  # ---- Kafka UI ----
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    networks: [stock_market]
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8082:8080" 
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      DYNAMIC_CONFIG_ENABLED: "true"
      # SPRING_SECURITY_USER_NAME: ${KAFKA_UI_USER}
      # SPRING_SECURITY_USER_PASSWORD: ${KAFKA_UI_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "bash -lc '</dev/tcp/127.0.0.1/8080' >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s

  # ---- Postgres ----
  postgres:
    image: postgres:16
    container_name: postgres
    networks: [stock_market]
    ports:
      - "5434:5432"
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-events}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
    volumes:
      - ./db_init:/docker-entrypoint-initdb.d:ro
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-events}"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 15s

  # ---- pgAdmin----
  pgadmin:
    image: dpage/pgadmin4:9
    container_name: pgadmin
    networks: [stock_market]
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@admin.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
    ports:
      - "5050:80"
    volumes:
      - ./pgadmin/servers.json:/pgadmin4/servers.json:ro
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/127.0.0.1/80' >/dev/null 2>&1"]
      interval: 15s
      timeout: 5s
      retries: 12
      start_period: 20s

networks:
  stock_market:
    driver: bridge    

volumes:
  postgres_data:
  spark_data:
  kafka_data:
  ivy_cache:
  spark_checkpoints:  
  